{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas\n",
    "import timm\n",
    "from torchsummary import summary\n",
    "import torch\n",
    "import torchvision\n",
    "fileName = r\"test.csv\"\n",
    "fileName2 = r\"train.csv\"\n",
    "\n",
    "test_dataset = pandas.read_csv(fileName)\n",
    "test_dataset.to_csv(\"temp.csv\")\n",
    "\n",
    "train_dataset = pandas.read_csv(fileName2)\n",
    "train_dataset.to_csv(\"temp2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "datatry =   torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "print(datatry.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64])\n",
      "tensor([[[-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01,  6.1244e+01,  2.4625e+02,\n",
      "           4.8318e+02,  8.2074e+02,  5.4810e+02,  4.4748e+02,  4.4748e+02,\n",
      "           3.5278e+01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "           3.5660e+02,  5.2213e+02,  5.2213e+02,  7.6556e+02,  8.1749e+02,\n",
      "           8.2074e+02,  8.1749e+02,  8.1749e+02,  8.1749e+02,  8.1749e+02,\n",
      "           4.4099e+02, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,  2.7546e+02,\n",
      "           8.2074e+02,  8.1749e+02,  8.1749e+02,  6.3249e+02,  5.9354e+02,\n",
      "           3.9555e+02,  2.9169e+02,  5.9354e+02,  7.7854e+02,  8.1749e+02,\n",
      "           8.0126e+02,  2.1704e+02, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,  5.0915e+02,\n",
      "           8.2074e+02,  8.1749e+02,  3.2739e+02,  2.8787e+01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01,  1.1967e+02,  3.1765e+02,\n",
      "           6.8442e+02,  7.2337e+02,  1.8133e+02, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,  7.4609e+02,\n",
      "           8.2074e+02,  7.4933e+02,  1.1967e+02, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "           4.4748e+02,  8.1749e+02,  2.2353e+02, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,  5.4485e+02,\n",
      "           8.2723e+02,  8.2074e+02,  2.5599e+02, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "           1.0993e+02,  7.7530e+02,  2.0405e+02, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,  3.0792e+02,\n",
      "           8.2074e+02,  8.1749e+02,  5.9354e+02, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "           3.6959e+02,  2.6897e+02,  1.5212e+02,  9.6947e+01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "           8.2074e+02,  8.1749e+02,  7.5907e+02,  4.6047e+02,  2.2296e+01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,  1.0344e+02,\n",
      "           2.6248e+02,  6.3898e+02,  8.1749e+02,  7.3635e+02,  5.4753e+01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "           3.7932e+02,  8.1749e+02,  8.1749e+02,  8.1749e+02,  3.4687e+02,\n",
      "           3.0143e+02,  3.0143e+02,  3.0143e+02,  6.0652e+02,  7.3960e+02,\n",
      "           8.2074e+02,  8.1749e+02,  8.1749e+02,  5.7082e+02,  1.2559e+01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "           9.3129e+00,  5.4810e+02,  8.1749e+02,  8.1749e+02,  8.1749e+02,\n",
      "           8.2074e+02,  8.1749e+02,  8.1749e+02,  8.1749e+02,  8.1749e+02,\n",
      "           8.2074e+02,  7.4933e+02,  4.4424e+02,  1.1318e+02, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01,  2.8787e+01,  7.7473e+01,\n",
      "           2.4625e+02,  5.5134e+02,  8.2074e+02,  8.2074e+02,  8.2074e+02,\n",
      "           8.2723e+02,  8.2074e+02,  8.0126e+02,  7.4609e+02,  4.0853e+02,\n",
      "           3.4362e+02, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01,  4.1770e+01,  5.6433e+02,  8.1749e+02,\n",
      "           8.2074e+02,  8.1749e+02,  8.1749e+02,  8.1749e+02,  8.1749e+02,\n",
      "           8.2074e+02,  8.1749e+02,  7.3635e+02,  9.3701e+01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01,  1.4563e+02,  5.5784e+02,  8.1749e+02,  8.1749e+02,\n",
      "           8.2074e+02,  6.7468e+02,  4.8968e+02,  2.2353e+02,  2.2353e+02,\n",
      "           7.2012e+02,  8.1749e+02,  8.1749e+02,  2.4949e+02, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "           6.1244e+01,  7.6556e+02,  8.1749e+02,  8.1749e+02,  8.1749e+02,\n",
      "           4.8643e+02,  5.4753e+01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "           1.1642e+02,  7.1038e+02,  8.1749e+02,  7.6556e+02,  1.9756e+02,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "           7.7473e+01,  8.1749e+02,  8.1749e+02,  8.1749e+02,  3.0792e+02,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01,  1.8458e+02,  8.1749e+02,  8.1749e+02,  4.4424e+02,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "           7.7473e+01,  8.2074e+02,  8.2074e+02,  5.2213e+02, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "           4.1770e+01,  3.8257e+02,  8.2074e+02,  8.2074e+02,  4.4424e+02,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "           7.7473e+01,  8.1749e+02,  8.1749e+02,  5.7406e+02,  1.5804e+01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,  1.3914e+02,\n",
      "           6.8766e+02,  8.1749e+02,  8.1749e+02,  8.1749e+02,  3.7932e+02,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "           5.4753e+01,  7.3635e+02,  8.1749e+02,  8.1749e+02,  6.1626e+02,\n",
      "           2.2677e+02,  2.9493e+02,  5.9678e+02,  5.9678e+02,  7.9802e+02,\n",
      "           8.2074e+02,  8.1749e+02,  8.1749e+02,  3.2739e+02,  1.9050e+01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01,  1.6186e+02,  7.3635e+02,  8.1749e+02,  8.1749e+02,\n",
      "           8.2074e+02,  8.1749e+02,  8.1749e+02,  8.1749e+02,  8.1749e+02,\n",
      "           8.2074e+02,  6.2600e+02,  2.4949e+02,  2.8787e+01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01,  5.4753e+01,  3.7932e+02,  6.1301e+02,\n",
      "           8.2074e+02,  8.1749e+02,  8.1749e+02,  8.1749e+02,  4.7669e+02,\n",
      "           2.4300e+02,  2.5541e+01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01]]])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(train_loader):\n",
    "    print(data[1].shape)\n",
    "    print(data[0][0])\n",
    "    print(type(data[1]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x265f0f6bbd0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 3\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_train = train_dataset.to_numpy()\n",
    "numpy_test = test_dataset.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   7.  24.\n",
      "   24.  97. 253. 253. 253. 253. 255. 180.  48.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  30. 186. 252.\n",
      "  252. 253. 252. 252. 252. 252. 253. 252. 227.  29.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  38. 155. 252. 252.\n",
      "  252. 253. 252. 252. 227.  79. 222. 252. 252. 129.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.  85. 233. 252. 252. 252.\n",
      "  252. 253. 252. 252. 202.  11. 180. 252. 252. 119.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.  43. 240. 253. 252. 252. 252.\n",
      "  252. 253. 252. 252. 244. 126. 201. 252. 252. 150.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   7. 212. 253. 255. 253. 253. 253.\n",
      "  232. 221.  42.   0. 104. 253. 255. 253. 205.  21.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.  25. 223. 252. 253. 252. 252. 214.\n",
      "   18.   0.   0.  34. 215. 252. 253. 223.  56.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.  99. 246. 253. 252. 252.  77.\n",
      "    0.   7.  70. 203. 252. 252. 173.  25.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.  42. 253. 252. 252. 236.\n",
      "  103. 160. 252. 252. 218. 108.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 148. 252. 252. 252.\n",
      "  252. 253. 231. 106.  14.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  24. 253. 253. 253.\n",
      "  253. 255. 159.   7.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.  43. 118. 252. 240. 244.\n",
      "  252. 253. 231.  37.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.  19. 164. 246. 253. 187.  50.  99.\n",
      "  246. 253. 252.  69.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.  80. 232. 252. 203.  58.   0.   0.\n",
      "  135. 253. 252. 121.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.  43. 246. 252. 200.  11.   0.   0.   0.\n",
      "  116. 253. 252.  69.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0. 162. 253. 192.  11.   0.   0.   0.   0.\n",
      "  179. 255. 253.  69.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   5. 178. 252. 119.   0.   5.  47.  47. 140.\n",
      "  244. 253. 252.  69.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   7. 186. 252. 227. 184. 191. 252. 252. 252.\n",
      "  252. 253. 240.  50.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.  11. 144. 227. 252. 252. 253. 252. 252. 252.\n",
      "  252.  98.  37.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.  48. 137. 242. 253. 231. 137. 137.\n",
      "   32.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(image)\n\u001b[1;32m---> 11\u001b[0m imgPil \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241m.\u001b[39mfromarray(image)\n\u001b[0;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(imgPil)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(numpy_train[index][\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "numpy_train.shape\n",
    "\n",
    "numpy_train[0]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "index = 10\n",
    "image = numpy_train[index][1:]\n",
    "image = image.reshape(28,28)\n",
    "image = image.astype('float')\n",
    "print(image)\n",
    "imgPil = Image.fromarray(image)\n",
    "plt.imshow(imgPil)\n",
    "print(numpy_train[index][0])\n",
    "print(imgPil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(numpy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "class MNISTDataLoader(Dataset):\n",
    "\n",
    "    def __init__(self, numpyDataset, transform = None):\n",
    "        self.data = numpyDataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return(len(self.data))\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        if(len(self.data[idx]) == 785):\n",
    "            img = self.data[idx][1:]\n",
    "        else:\n",
    "            img = self.data[idx]\n",
    "        img = img.reshape(28,28)\n",
    "        #print(img.dtype)\n",
    "        img = img.astype('float32')\n",
    "        #print(img)\n",
    "        #print(img.shape)\n",
    "        #img = np.expand_dims(img,0)\n",
    "        img = Image.fromarray(img)\n",
    "        print(img)\n",
    "        #img = img.astype('float32')\n",
    "        label = self.data[idx][0]\n",
    "        label_tensor = torch.tensor(label)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        \n",
    "        return(img,label_tensor)      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))])\n",
    "#labelTransform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "\n",
    "MnistTrainDataset = MNISTDataLoader(numpy_train,transform)\n",
    "MnistTestDataset = MNISTDataLoader(numpy_test,transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(MnistTrainDataset,batch_size=64,shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(MnistTestDataset,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "<PIL.Image.Image image mode=F size=28x28 at 0x265AAE6E9A0>\n",
      "torch.Size([64])\n",
      "tensor([[[-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,  4.9292e+02,\n",
      "           7.6556e+02,  2.4949e+02, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01,  4.2152e+02,  8.2398e+02,\n",
      "           8.2398e+02,  5.1889e+02, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01,  1.0993e+02,  3.6634e+02,  6.7735e+01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01,  3.3388e+02,  7.9802e+02,  8.2398e+02,\n",
      "           8.2398e+02,  4.0529e+02, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "           5.7998e+01,  6.9416e+02,  8.2398e+02,  5.9029e+02, -4.2421e-01,\n",
      "          -4.2421e-01,  7.0981e+01,  7.1038e+02,  8.2398e+02,  7.1688e+02,\n",
      "           4.1827e+02,  1.0344e+02, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,  6.0672e+00,\n",
      "           5.6757e+02,  8.2398e+02,  8.2398e+02,  4.0853e+02, -4.2421e-01,\n",
      "          -4.2421e-01,  3.7608e+02,  8.2398e+02,  8.2398e+02,  4.7994e+02,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,  4.0204e+02,\n",
      "           8.2398e+02,  8.2398e+02,  7.2661e+02,  1.0993e+02, -4.2421e-01,\n",
      "           1.9107e+02,  7.7854e+02,  8.2398e+02,  7.2337e+02,  9.3701e+01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01,  8.0718e+01,  7.7205e+02,\n",
      "           8.2398e+02,  7.3310e+02,  1.0019e+02, -4.2421e-01, -4.2421e-01,\n",
      "           3.9555e+02,  8.2398e+02,  8.2398e+02,  4.6696e+02, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01,  5.8705e+02,  8.2398e+02,\n",
      "           8.2398e+02,  2.6572e+02, -4.2421e-01, -4.2421e-01,  4.1770e+01,\n",
      "           7.2012e+02,  8.2398e+02,  7.3310e+02,  1.0019e+02, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01,  5.7998e+01,  7.4284e+02,  8.2398e+02,\n",
      "           7.3310e+02,  1.9050e+01, -4.2421e-01, -4.2421e-01,  4.1503e+02,\n",
      "           8.2398e+02,  8.2398e+02,  5.9029e+02,  1.9107e+02,  1.9107e+02,\n",
      "           1.9107e+02,  1.6186e+02, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01,  1.4239e+02,  8.1100e+02,  8.2398e+02,\n",
      "           7.8828e+02,  6.2924e+02,  4.3450e+02,  6.0328e+02,  7.7854e+02,\n",
      "           8.2398e+02,  8.2398e+02,  8.2398e+02,  8.2398e+02,  8.2398e+02,\n",
      "           8.2398e+02,  7.3960e+02,  5.7998e+01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01,  8.3964e+01,  7.6556e+02,  8.2398e+02,\n",
      "           8.2398e+02,  8.2398e+02,  8.2398e+02,  8.2398e+02,  8.2398e+02,\n",
      "           8.2398e+02,  8.2398e+02,  8.2398e+02,  8.2398e+02,  8.2398e+02,\n",
      "           8.2398e+02,  5.1889e+02, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01,  3.0143e+02,  7.0714e+02,\n",
      "           7.6881e+02,  7.6881e+02,  8.0451e+02,  8.2398e+02,  8.2398e+02,\n",
      "           7.6232e+02,  3.5660e+02,  1.8783e+02,  1.8783e+02,  1.8783e+02,\n",
      "           1.8783e+02,  2.5541e+01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01,  5.2213e+02,  8.2398e+02,  8.2398e+02,\n",
      "           4.2801e+02, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01,  7.1688e+02,  8.2398e+02,  7.7854e+02,\n",
      "           1.0019e+02, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01,  4.4424e+02,  8.2398e+02,  8.2398e+02,  4.0204e+02,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01,  5.6757e+02,  8.2398e+02,  8.2398e+02,  3.9231e+02,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "           2.5541e+01,  7.9153e+02,  8.2398e+02,  7.9477e+02,  1.2616e+02,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "           3.9880e+02,  8.2398e+02,  8.2398e+02,  4.0204e+02, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "           6.0977e+02,  8.2398e+02,  8.2398e+02,  3.3388e+02, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "           1.9107e+02,  7.3310e+02,  5.5784e+02,  1.9050e+01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01],\n",
      "         [-4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01, -4.2421e-01,\n",
      "          -4.2421e-01, -4.2421e-01, -4.2421e-01]]])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(train_loader):\n",
    "    print(data[1].shape)\n",
    "    print(data[0][0])\n",
    "    print(type(data[1]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[1].shape\n",
    "#plt.imshow(sample[0][0].squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000 28000\n"
     ]
    }
   ],
   "source": [
    "print(len(numpy_train),len(numpy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "    \n",
    "        self.conv1 = nn.Conv2d(1,10,kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10,20,kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320,50)\n",
    "        self.fc2 = nn.Linear(50,10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x),2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)),2))\n",
    "        x = x.view(-1,320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x,training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "network = Net()\n",
    "network = network.to(device)\n",
    "\n",
    "optimizer = optim.SGD(network.parameters(), lr = learning_rate,momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "  network.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    data,target = data.to(device),target.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    output = network(data)\n",
    "    print(\"Target\",target)\n",
    "    print(\"output\", output)\n",
    "    break\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx % log_interval == 0:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        100. * batch_idx / len(train_loader), loss.item()))\n",
    "      train_losses.append(loss.item())\n",
    "      train_counter.append(\n",
    "        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "      # torch.save(network.state_dict(), '/results/model.pth')\n",
    "      # torch.save(optimizer.state_dict(), '/results/optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "  network.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      data,target = data.to(device),target.to(device)\n",
    "      output = network(data)\n",
    "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  test_losses.append(test_loss)\n",
    "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Khalil\\AppData\\Local\\Temp\\ipykernel_31128\\139046024.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n",
      "c:\\Users\\Khalil\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: nan, Accuracy: 28000/28000 (100%)\n",
      "\n",
      "Target tensor([6, 3, 9, 6, 8, 5, 4, 8, 6, 7, 7, 1, 9, 9, 9, 3, 1, 9, 9, 6, 5, 4, 9, 1,\n",
      "        6, 5, 3, 4, 2, 8, 3, 7, 1, 7, 6, 2, 9, 2, 7, 9, 4, 8, 7, 8, 8, 6, 7, 9,\n",
      "        9, 7, 2, 9, 4, 4, 2, 9, 4, 2, 5, 0, 9, 0, 0, 9], device='cuda:0')\n",
      "output tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Target tensor([6, 9, 7, 8, 3, 1, 3, 2, 5, 9, 3, 0, 7, 0, 5, 1, 6, 7, 8, 8, 8, 4, 3, 1,\n",
      "        5, 0, 0, 1, 0, 4, 1, 4, 9, 7, 8, 0, 9, 5, 9, 3, 3, 4, 3, 4, 6, 1, 5, 8,\n",
      "        9, 6, 3, 8, 7, 3, 8, 7, 1, 2, 2, 6, 3, 7, 0, 1], device='cuda:0')\n",
      "output tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "Target tensor([2, 1, 7, 7, 8, 8, 8, 6, 6, 4, 2, 0, 8, 0, 7, 4, 3, 8, 9, 2, 2, 9, 7, 2,\n",
      "        4, 5, 1, 9, 1, 8, 0, 8, 2, 8, 7, 4, 6, 9, 2, 1, 0, 9, 4, 2, 2, 9, 9, 1,\n",
      "        9, 2, 0, 6, 1, 8, 0, 4, 5, 5, 6, 7, 6, 6, 2, 2], device='cuda:0')\n",
      "output tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]], device='cuda:0',\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  train(epoch)\n",
    "  #test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
